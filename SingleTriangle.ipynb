{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.1.4-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 9.9 MB/s eta 0:00:01     |█████████████████████████████▋  | 8.8 MB 9.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2017.2\n",
      "  Downloading pytz-2020.4-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[K     |████████████████████████████████| 509 kB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.1.4 pytz-2020.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as tfk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked funktion benyttet af Kuo i Deep Triangle\n",
    "def masked_mse(mask_value): \n",
    "   # y_true, y_pred kommer fra tensorflow kørsel\n",
    "   def masked_calc(y_true, y_pred):\n",
    "       keep_value        = tfk.cast(tfk.not_equal(y_true,mask_value),tfk.floatx()) \n",
    "       sum_squared_error = tfk.sum(tfk.square(keep_value * (y_true - y_pred)), axis = 2)\n",
    "       return (sum_squared_error / tfk.sum(keep_value, axis = 2))\n",
    "   return masked_calc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mse(y_true, y_pred):\n",
    "# assume 1st dimension is the number of samples\n",
    "    mask = y_true != mask_value\n",
    "    mse = tfk.mean(tfk.square((y_pred-y_true)*mask))\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_mse <- function(mask_value) {\n",
    "  function(y_true, y_pred) {\n",
    "    keep_value <- k_cast(k_not_equal(y_true, mask_value), k_floatx())\n",
    "    sum_squared_error <- k_sum(\n",
    "      k_square(keep_value * (y_true - y_pred)),\n",
    "      axis = 2\n",
    "    )\n",
    "    sum_squared_error / k_sum(keep_value, axis = 2)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"x.csv\", sep=\";\", decimal=\",\")\n",
    "x.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "y = pd.read_csv(\"y.csv\", sep=\";\", decimal=\",\")\n",
    "y.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "validation = pd.read_csv(\"validation.csv\", sep=\";\", decimal=\",\")\n",
    "validation.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-23db21bb3ce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_df' is not defined"
     ]
    }
   ],
   "source": [
    "x.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.073245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.073245</td>\n",
       "      <td>0.050865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.073245</td>\n",
       "      <td>0.050865</td>\n",
       "      <td>0.020346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.073245</td>\n",
       "      <td>0.050865</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.014242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.073245</td>\n",
       "      <td>0.050865</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.014242</td>\n",
       "      <td>0.011190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.073245</td>\n",
       "      <td>0.050865</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.014242</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.008138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.073245</td>\n",
       "      <td>0.050865</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.014242</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.005086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.073245</td>\n",
       "      <td>0.050865</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.014242</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.073245</td>\n",
       "      <td>0.050865</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.014242</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.003052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.118467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.118467</td>\n",
       "      <td>0.108014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.118467</td>\n",
       "      <td>0.108014</td>\n",
       "      <td>0.033101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.118467</td>\n",
       "      <td>0.108014</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.040070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.118467</td>\n",
       "      <td>0.108014</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.040070</td>\n",
       "      <td>0.081882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.118467</td>\n",
       "      <td>0.108014</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.040070</td>\n",
       "      <td>0.081882</td>\n",
       "      <td>0.013937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.118467</td>\n",
       "      <td>0.108014</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.040070</td>\n",
       "      <td>0.081882</td>\n",
       "      <td>0.013937</td>\n",
       "      <td>0.005226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.118467</td>\n",
       "      <td>0.108014</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.040070</td>\n",
       "      <td>0.081882</td>\n",
       "      <td>0.013937</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>0.003484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.178423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.178423</td>\n",
       "      <td>0.123098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.178423</td>\n",
       "      <td>0.123098</td>\n",
       "      <td>0.149378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.178423</td>\n",
       "      <td>0.123098</td>\n",
       "      <td>0.149378</td>\n",
       "      <td>0.087137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.178423</td>\n",
       "      <td>0.123098</td>\n",
       "      <td>0.149378</td>\n",
       "      <td>0.087137</td>\n",
       "      <td>0.008299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.178423</td>\n",
       "      <td>0.123098</td>\n",
       "      <td>0.149378</td>\n",
       "      <td>0.087137</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.006916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.178423</td>\n",
       "      <td>0.123098</td>\n",
       "      <td>0.149378</td>\n",
       "      <td>0.087137</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>0.004149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.344015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.344015</td>\n",
       "      <td>0.161169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.344015</td>\n",
       "      <td>0.161169</td>\n",
       "      <td>0.035815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.344015</td>\n",
       "      <td>0.161169</td>\n",
       "      <td>0.035815</td>\n",
       "      <td>0.096136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.344015</td>\n",
       "      <td>0.161169</td>\n",
       "      <td>0.035815</td>\n",
       "      <td>0.096136</td>\n",
       "      <td>0.015080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.344015</td>\n",
       "      <td>0.161169</td>\n",
       "      <td>0.035815</td>\n",
       "      <td>0.096136</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>0.066918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.120999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.120999</td>\n",
       "      <td>0.055425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.120999</td>\n",
       "      <td>0.055425</td>\n",
       "      <td>0.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.120999</td>\n",
       "      <td>0.055425</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.187354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.120999</td>\n",
       "      <td>0.055425</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.187354</td>\n",
       "      <td>0.030445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.130653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.130653</td>\n",
       "      <td>0.109835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.130653</td>\n",
       "      <td>0.109835</td>\n",
       "      <td>0.194544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.130653</td>\n",
       "      <td>0.109835</td>\n",
       "      <td>0.194544</td>\n",
       "      <td>0.142139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.145390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.145390</td>\n",
       "      <td>0.109338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.145390</td>\n",
       "      <td>0.109338</td>\n",
       "      <td>0.156028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.164843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.164843</td>\n",
       "      <td>0.099198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.127941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5  \\\n",
       "0  -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "1  -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "2  -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "3  -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   0.073245   \n",
       "4  -99.000000 -99.000000 -99.000000 -99.000000   0.073245   0.050865   \n",
       "5  -99.000000 -99.000000 -99.000000   0.073245   0.050865   0.020346   \n",
       "6  -99.000000 -99.000000   0.073245   0.050865   0.020346   0.014242   \n",
       "7  -99.000000   0.073245   0.050865   0.020346   0.014242   0.011190   \n",
       "8    0.073245   0.050865   0.020346   0.014242   0.011190   0.008138   \n",
       "9  -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "10 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "11 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "12 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   0.118467   \n",
       "13 -99.000000 -99.000000 -99.000000 -99.000000   0.118467   0.108014   \n",
       "14 -99.000000 -99.000000 -99.000000   0.118467   0.108014   0.033101   \n",
       "15 -99.000000 -99.000000   0.118467   0.108014   0.033101   0.040070   \n",
       "16 -99.000000   0.118467   0.108014   0.033101   0.040070   0.081882   \n",
       "17 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "18 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "19 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "20 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   0.178423   \n",
       "21 -99.000000 -99.000000 -99.000000 -99.000000   0.178423   0.123098   \n",
       "22 -99.000000 -99.000000 -99.000000   0.178423   0.123098   0.149378   \n",
       "23 -99.000000 -99.000000   0.178423   0.123098   0.149378   0.087137   \n",
       "24 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "25 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "26 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "27 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   0.344015   \n",
       "28 -99.000000 -99.000000 -99.000000 -99.000000   0.344015   0.161169   \n",
       "29 -99.000000 -99.000000 -99.000000   0.344015   0.161169   0.035815   \n",
       "30 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "31 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "32 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "33 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   0.120999   \n",
       "34 -99.000000 -99.000000 -99.000000 -99.000000   0.120999   0.055425   \n",
       "35 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "36 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "37 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "38 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   0.130653   \n",
       "39 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "40 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "41 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "42 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "43 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "44 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000 -99.000000   \n",
       "\n",
       "            6          7         8  \n",
       "0  -99.000000 -99.000000  0.073245  \n",
       "1  -99.000000   0.073245  0.050865  \n",
       "2    0.073245   0.050865  0.020346  \n",
       "3    0.050865   0.020346  0.014242  \n",
       "4    0.020346   0.014242  0.011190  \n",
       "5    0.014242   0.011190  0.008138  \n",
       "6    0.011190   0.008138  0.005086  \n",
       "7    0.008138   0.005086  0.001017  \n",
       "8    0.005086   0.001017  0.003052  \n",
       "9  -99.000000 -99.000000  0.118467  \n",
       "10 -99.000000   0.118467  0.108014  \n",
       "11   0.118467   0.108014  0.033101  \n",
       "12   0.108014   0.033101  0.040070  \n",
       "13   0.033101   0.040070  0.081882  \n",
       "14   0.040070   0.081882  0.013937  \n",
       "15   0.081882   0.013937  0.005226  \n",
       "16   0.013937   0.005226  0.003484  \n",
       "17 -99.000000 -99.000000  0.178423  \n",
       "18 -99.000000   0.178423  0.123098  \n",
       "19   0.178423   0.123098  0.149378  \n",
       "20   0.123098   0.149378  0.087137  \n",
       "21   0.149378   0.087137  0.008299  \n",
       "22   0.087137   0.008299  0.006916  \n",
       "23   0.008299   0.006916  0.004149  \n",
       "24 -99.000000 -99.000000  0.344015  \n",
       "25 -99.000000   0.344015  0.161169  \n",
       "26   0.344015   0.161169  0.035815  \n",
       "27   0.161169   0.035815  0.096136  \n",
       "28   0.035815   0.096136  0.015080  \n",
       "29   0.096136   0.015080  0.066918  \n",
       "30 -99.000000 -99.000000  0.120999  \n",
       "31 -99.000000   0.120999  0.055425  \n",
       "32   0.120999   0.055425  0.065574  \n",
       "33   0.055425   0.065574  0.187354  \n",
       "34   0.065574   0.187354  0.030445  \n",
       "35 -99.000000 -99.000000  0.130653  \n",
       "36 -99.000000   0.130653  0.109835  \n",
       "37   0.130653   0.109835  0.194544  \n",
       "38   0.109835   0.194544  0.142139  \n",
       "39 -99.000000 -99.000000  0.145390  \n",
       "40 -99.000000   0.145390  0.109338  \n",
       "41   0.145390   0.109338  0.156028  \n",
       "42 -99.000000 -99.000000  0.164843  \n",
       "43 -99.000000   0.164843  0.099198  \n",
       "44 -99.000000 -99.000000  0.127941  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_single.reshape(45,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_single = x[x[\"group_code\"] ==0]\n",
    "x_single = x_single[x_single.columns[:9]].to_numpy()\n",
    "x_single = x_single[:,:,np.newaxis]\n",
    "\n",
    "val_single = validation[validation[\"x.group_code\"] ==0]\n",
    "validation_single_x = val_single[val_single.columns[:9]].to_numpy()\n",
    "validation_single_x = validation_single_x[:,:,np.newaxis]\n",
    "validation_single_y = val_single[val_single.columns[val_single.columns.str.startswith(\"y.paid_\")]].to_numpy()\n",
    "validation_single_y = validation_single_y[:,:,np.newaxis]\n",
    "\n",
    "y_single = y[x[\"group_code\"] ==0]\n",
    "y_single = y_single[y_single.columns[:9]].to_numpy()\n",
    "y_single = y_single[:,:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (45, 9, 1), y shape : (45, 9, 1),  validation x shape : (17, 9, 1),  validation y shape : (17, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x shape: {x_single.shape}, y shape : {y_single.shape},  validation x shape : {validation_single_x.shape},  validation y shape : {validation_single_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell definisjon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed, GRU, Dense, RepeatVector, LSTM\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 9, 1)              0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                16896     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 9, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 9, 64)             33024     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 9, 1)              65        \n",
      "=================================================================\n",
      "Total params: 49,985\n",
      "Trainable params: 49,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# encoder layer\n",
    "model.add(layers.Masking(mask_value = -99, input_shape = (9,1)))\n",
    "model.add(layers.LSTM(64, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "\n",
    "# repeat vector\n",
    "model.add(RepeatVector(9))\n",
    "\n",
    "# decoder layer\n",
    "model.add(layers.LSTM(64, return_sequences = True, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45 samples\n",
      "Epoch 1/100\n",
      "45/45 [==============================] - 3s 58ms/sample - loss: 5808.0889\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 657us/sample - loss: 5806.2739\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 712us/sample - loss: 5804.3037\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 756us/sample - loss: 5802.4888\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 727us/sample - loss: 5800.3706\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 675us/sample - loss: 5797.8672\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 651us/sample - loss: 5795.5557\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 703us/sample - loss: 5792.2788\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 674us/sample - loss: 5788.8730\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 742us/sample - loss: 5786.0840\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 636us/sample - loss: 5780.4771\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 550us/sample - loss: 5776.4033\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 736us/sample - loss: 5769.4771\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 680us/sample - loss: 5763.3345\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 707us/sample - loss: 5754.6245\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 758us/sample - loss: 5743.9678\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 657us/sample - loss: 5732.5601\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 649us/sample - loss: 5717.1333\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 639us/sample - loss: 5700.8735\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 716us/sample - loss: 5679.1230\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 679us/sample - loss: 5648.4434\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 674us/sample - loss: 5613.4927\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 710us/sample - loss: 5574.5605\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 647us/sample - loss: 5528.7715\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 639us/sample - loss: 5475.9688\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 699us/sample - loss: 5411.9785\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 651us/sample - loss: 5353.2061\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 648us/sample - loss: 5295.7866\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 657us/sample - loss: 5227.9033\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 635us/sample - loss: 5167.6606\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 800us/sample - loss: 5108.2642\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 737us/sample - loss: 5060.0806\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 638us/sample - loss: 4993.5273\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 712us/sample - loss: 4953.8672\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 680us/sample - loss: 4900.0122\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 639us/sample - loss: 4860.2515\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 626us/sample - loss: 4818.9600\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 710us/sample - loss: 4783.2554\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 672us/sample - loss: 4753.2695\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 702us/sample - loss: 4721.7388\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 0s 753us/sample - loss: 4700.6641\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 0s 972us/sample - loss: 4671.6060\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 0s 783us/sample - loss: 4649.4619\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 0s 788us/sample - loss: 4629.8877\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 0s 851us/sample - loss: 4611.1348\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 0s 871us/sample - loss: 4593.4033\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 0s 737us/sample - loss: 4573.8931\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 0s 775us/sample - loss: 4556.2065\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 0s 843us/sample - loss: 4541.1006\n",
      "Epoch 50/100\n",
      "45/45 [==============================] - 0s 888us/sample - loss: 4526.9634\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 0s 716us/sample - loss: 4511.6626\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 0s 795us/sample - loss: 4499.7051\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 0s 798us/sample - loss: 4487.0366\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 0s 720us/sample - loss: 4475.7935\n",
      "Epoch 55/100\n",
      "45/45 [==============================] - 0s 858us/sample - loss: 4468.6025\n",
      "Epoch 56/100\n",
      "45/45 [==============================] - 0s 750us/sample - loss: 4453.4756\n",
      "Epoch 57/100\n",
      "45/45 [==============================] - 0s 768us/sample - loss: 4441.8579\n",
      "Epoch 58/100\n",
      "45/45 [==============================] - 0s 861us/sample - loss: 4432.2168\n",
      "Epoch 59/100\n",
      "45/45 [==============================] - 0s 715us/sample - loss: 4421.8452\n",
      "Epoch 60/100\n",
      "45/45 [==============================] - 0s 668us/sample - loss: 4410.9243\n",
      "Epoch 61/100\n",
      "45/45 [==============================] - 0s 632us/sample - loss: 4398.4873\n",
      "Epoch 62/100\n",
      "45/45 [==============================] - 0s 654us/sample - loss: 4389.9834\n",
      "Epoch 63/100\n",
      "45/45 [==============================] - 0s 629us/sample - loss: 4378.0356\n",
      "Epoch 64/100\n",
      "45/45 [==============================] - 0s 650us/sample - loss: 4366.8057\n",
      "Epoch 65/100\n",
      "45/45 [==============================] - 0s 612us/sample - loss: 4362.0249\n",
      "Epoch 66/100\n",
      "45/45 [==============================] - 0s 611us/sample - loss: 4351.6382\n",
      "Epoch 67/100\n",
      "45/45 [==============================] - 0s 666us/sample - loss: 4343.1797\n",
      "Epoch 68/100\n",
      "45/45 [==============================] - 0s 652us/sample - loss: 4331.7017\n",
      "Epoch 69/100\n",
      "45/45 [==============================] - 0s 629us/sample - loss: 4320.8442\n",
      "Epoch 70/100\n",
      "45/45 [==============================] - 0s 757us/sample - loss: 4316.4194\n",
      "Epoch 71/100\n",
      "45/45 [==============================] - 0s 666us/sample - loss: 4308.9653\n",
      "Epoch 72/100\n",
      "45/45 [==============================] - 0s 619us/sample - loss: 4298.4009\n",
      "Epoch 73/100\n",
      "45/45 [==============================] - 0s 668us/sample - loss: 4288.8945\n",
      "Epoch 74/100\n",
      "45/45 [==============================] - 0s 696us/sample - loss: 4283.0625\n",
      "Epoch 75/100\n",
      "45/45 [==============================] - 0s 756us/sample - loss: 4272.7544\n",
      "Epoch 76/100\n",
      "45/45 [==============================] - 0s 698us/sample - loss: 4262.6924\n",
      "Epoch 77/100\n",
      "45/45 [==============================] - 0s 584us/sample - loss: 4256.4038\n",
      "Epoch 78/100\n",
      "45/45 [==============================] - 0s 598us/sample - loss: 4250.4282\n",
      "Epoch 79/100\n",
      "45/45 [==============================] - 0s 620us/sample - loss: 4240.4946\n",
      "Epoch 80/100\n",
      "45/45 [==============================] - 0s 625us/sample - loss: 4235.7251\n",
      "Epoch 81/100\n",
      "45/45 [==============================] - 0s 647us/sample - loss: 4227.0718\n",
      "Epoch 82/100\n",
      "45/45 [==============================] - 0s 662us/sample - loss: 4218.1768\n",
      "Epoch 83/100\n",
      "45/45 [==============================] - 0s 616us/sample - loss: 4211.8291\n",
      "Epoch 84/100\n",
      "45/45 [==============================] - 0s 653us/sample - loss: 4202.1885\n",
      "Epoch 85/100\n",
      "45/45 [==============================] - 0s 604us/sample - loss: 4193.9131\n",
      "Epoch 86/100\n",
      "45/45 [==============================] - 0s 656us/sample - loss: 4186.9497\n",
      "Epoch 87/100\n",
      "45/45 [==============================] - 0s 676us/sample - loss: 4178.3770\n",
      "Epoch 88/100\n",
      "45/45 [==============================] - 0s 585us/sample - loss: 4171.7310\n",
      "Epoch 89/100\n",
      "45/45 [==============================] - 0s 630us/sample - loss: 4164.4648\n",
      "Epoch 90/100\n",
      "45/45 [==============================] - 0s 553us/sample - loss: 4157.6689\n",
      "Epoch 91/100\n",
      "45/45 [==============================] - 0s 597us/sample - loss: 4151.5938\n",
      "Epoch 92/100\n",
      "45/45 [==============================] - 0s 644us/sample - loss: 4141.7563\n",
      "Epoch 93/100\n",
      "45/45 [==============================] - 0s 702us/sample - loss: 4134.3931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "45/45 [==============================] - 0s 645us/sample - loss: 4126.8599\n",
      "Epoch 95/100\n",
      "45/45 [==============================] - 0s 582us/sample - loss: 4122.1226\n",
      "Epoch 96/100\n",
      "45/45 [==============================] - 0s 843us/sample - loss: 4114.0605\n",
      "Epoch 97/100\n",
      "45/45 [==============================] - 0s 631us/sample - loss: 4105.9697\n",
      "Epoch 98/100\n",
      "45/45 [==============================] - 0s 599us/sample - loss: 4103.7148\n",
      "Epoch 99/100\n",
      "45/45 [==============================] - 0s 616us/sample - loss: 4094.1516\n",
      "Epoch 100/100\n",
      "45/45 [==============================] - 0s 589us/sample - loss: 4086.4529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd0a36b9f98>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x= x_single,\n",
    "             y= y_single,\n",
    "             batch_size = 2250,\n",
    "             epochs = 100,\n",
    "             verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ay_seq_input  = layers.Input(shape = (9,1))\n",
    "\n",
    "encoded = layers.Masking(mask_value = -99)(ay_seq_input)\n",
    "encoded = layers.GRU(64, dropout = 0.2, recurrent_dropout = 0.2)(encoded)\n",
    "\n",
    "decoded = layers.RepeatVector(9)(encoded)\n",
    "decoded = layers.GRU(64, return_sequences = True, dropout = 0.2, recurrent_dropout = 0.2)(decoded)\n",
    "\n",
    "\n",
    "paid_output = layers.TimeDistributed(layers.Dense(units = 32, activation = \"relu\"))(decoded)\n",
    "paid_output1 = layers.TimeDistributed(layers.Dropout(rate = 0.2))(paid_output)\n",
    "paid_output2 = layers.TimeDistributed(layers.Dense(units = 1, activation = \"relu\"), name = \"paid_output\")(paid_output1)\n",
    "\n",
    "model = keras.Model(\n",
    "inputs = ay_seq_input,\n",
    "outputs = paid_output2, name=\"DeepTriangle\"\n",
    ")\n",
    "model.compile(optimizer = Adam(learning_rate=0.001, amsgrad = True),\n",
    "            loss         = [masked_mse(missing_value)],\n",
    "            loss_weights = [0.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DeepTriangle\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 9, 1)]            0         \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 9, 1)              0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                16896     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 9, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 9, 64)             33024     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 9, 32)             2080      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "paid_output (TimeDistributed (None, 9, 1)              33        \n",
      "=================================================================\n",
      "Total params: 52,033\n",
      "Trainable params: 52,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_first_model.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell - fit og predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse(missing_value):\n",
    "    \n",
    "    def custom_mse(y_true, y_pred):\n",
    "    # assume 1st dimension is the number of samples\n",
    "        mask = y_true != missing_value\n",
    "        mse = tfk.mean(tfk.square((y_pred-y_true)*mask, axis=2), axis=2)\n",
    "\n",
    "        return mse\n",
    "\n",
    "    return custom_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfk.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "45/45 [==============================] - 0s 660us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 723us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 616us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 583us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 554us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 591us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 556us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 633us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 574us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 576us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 611us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 550us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 639us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 547us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 670us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 608us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 604us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 619us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 660us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 708us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 596us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 585us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 558us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 591us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 555us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 652us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 647us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 555us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 574us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 621us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 541us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 636us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 634us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 625us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 625us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 598us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 641us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 635us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 549us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 609us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 0s 559us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 0s 583us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 0s 603us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 0s 700us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 0s 629us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 0s 616us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 0s 666us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 0s 829us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 0s 1ms/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 50/100\n",
      "45/45 [==============================] - 0s 727us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 0s 677us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 0s 647us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 0s 632us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 0s 585us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 55/100\n",
      "45/45 [==============================] - 0s 618us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 56/100\n",
      "45/45 [==============================] - 0s 712us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 57/100\n",
      "45/45 [==============================] - 0s 626us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 58/100\n",
      "45/45 [==============================] - 0s 746us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 59/100\n",
      "45/45 [==============================] - 0s 739us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 60/100\n",
      "45/45 [==============================] - 0s 596us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 61/100\n",
      "45/45 [==============================] - 0s 595us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 62/100\n",
      "45/45 [==============================] - 0s 599us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 63/100\n",
      "45/45 [==============================] - 0s 650us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 64/100\n",
      "45/45 [==============================] - 0s 652us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 65/100\n",
      "45/45 [==============================] - 0s 666us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 66/100\n",
      "45/45 [==============================] - 0s 615us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 67/100\n",
      "45/45 [==============================] - 0s 610us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 68/100\n",
      "45/45 [==============================] - 0s 624us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 69/100\n",
      "45/45 [==============================] - 0s 638us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 70/100\n",
      "45/45 [==============================] - 0s 608us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 71/100\n",
      "45/45 [==============================] - 0s 626us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 72/100\n",
      "45/45 [==============================] - 0s 607us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 73/100\n",
      "45/45 [==============================] - 0s 634us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 74/100\n",
      "45/45 [==============================] - 0s 610us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 631us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 76/100\n",
      "45/45 [==============================] - 0s 611us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 77/100\n",
      "45/45 [==============================] - 0s 600us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 78/100\n",
      "45/45 [==============================] - 0s 605us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 79/100\n",
      "45/45 [==============================] - 0s 625us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 80/100\n",
      "45/45 [==============================] - 0s 648us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 81/100\n",
      "45/45 [==============================] - 0s 638us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 82/100\n",
      "45/45 [==============================] - 0s 624us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 83/100\n",
      "45/45 [==============================] - 0s 625us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 84/100\n",
      "45/45 [==============================] - 0s 635us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 85/100\n",
      "45/45 [==============================] - 0s 602us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 86/100\n",
      "45/45 [==============================] - 0s 627us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 87/100\n",
      "45/45 [==============================] - 0s 675us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 88/100\n",
      "45/45 [==============================] - 0s 587us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 89/100\n",
      "45/45 [==============================] - 0s 593us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 90/100\n",
      "45/45 [==============================] - 0s 567us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 91/100\n",
      "45/45 [==============================] - 0s 599us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 92/100\n",
      "45/45 [==============================] - 0s 626us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 93/100\n",
      "45/45 [==============================] - 0s 582us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 94/100\n",
      "45/45 [==============================] - 0s 564us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 95/100\n",
      "45/45 [==============================] - 0s 577us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 96/100\n",
      "45/45 [==============================] - 0s 575us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 97/100\n",
      "45/45 [==============================] - 0s 576us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 98/100\n",
      "45/45 [==============================] - 0s 619us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 99/100\n",
      "45/45 [==============================] - 0s 693us/sample - loss: 2904.0007 - val_loss: 4099.7646\n",
      "Epoch 100/100\n",
      "45/45 [==============================] - 0s 597us/sample - loss: 2904.0007 - val_loss: 4099.7646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd05e8a0780>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### beregner model\n",
    "#tfk.clear_session()\n",
    "\n",
    "#beregn_model.fit(x= X_train,y= y_train, batch_size = X_dim1, epochs = 99, callbacks = (callback), verbose = 0) KRÆVER valideringsdata\n",
    "\n",
    "model.fit(x= x_single,\n",
    "             y= y_single,\n",
    "             batch_size = 2250,\n",
    "             epochs = 100,\n",
    "            validation_data=(validation_single_x, validation_single_y),\n",
    "             callbacks =[callback],\n",
    "             verbose = 1)\n",
    "\n",
    "#Y_ibnr = model.predict(X_ibnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
